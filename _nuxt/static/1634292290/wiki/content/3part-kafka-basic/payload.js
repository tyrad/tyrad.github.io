__NUXT_JSONP__("/wiki/content/3part-kafka-basic", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S){return {data:[{},{article:{slug:u,title:v,layout:"page",date:w,toc:[{id:m,depth:x,text:m},{id:n,depth:o,text:n},{id:y,depth:o,text:z},{id:A,depth:x,text:B},{id:p,depth:o,text:p},{id:q,depth:o,text:q}],body:{type:"root",children:[{type:b,tag:e,props:{},children:[{type:b,tag:g,props:{href:"https:\u002F\u002Fwww.w3cschool.cn\u002Fapache_kafka\u002Fapache_kafka_introduction.html",rel:[C,D,E],target:F},children:[{type:a,value:"主要转载出处"}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"Kafka专为分布式高吞吐量系统而设计。适合于大规模的消息处理。"}]},{type:a,value:c},{type:b,tag:G,props:{id:m},children:[{type:b,tag:g,props:{href:"#%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F",ariaHidden:h,tabIndex:i},children:[{type:b,tag:j,props:{className:[k,l]},children:[]}]},{type:b,tag:"em",props:{},children:[{type:b,tag:"strong",props:{},children:[{type:a,value:m}]}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"消息系统负责将数据从一个应用程序传输到另一个应用程序，因此应用程序可以专注于数据，但不担心如何共享它。 分布式消息传递基于可靠消息队列的概念。 消息在客户端应用程序和消息传递系统之间异步排队。"}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"有两种类型的消息模式可用 - 一种是点对点，另一种是发布 - 订阅(pub-sub)消息系统。 大多数消息模式遵循 pub-sub 。"}]},{type:a,value:c},{type:b,tag:r,props:{id:n},children:[{type:b,tag:g,props:{href:"#%E7%82%B9%E5%AF%B9%E7%82%B9%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F",ariaHidden:h,tabIndex:i},children:[{type:b,tag:j,props:{className:[k,l]},children:[]}]},{type:a,value:n}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"消息被保留在队列中。 一个或多个消费者可以消耗队列中的消息，但是"},{type:b,tag:s,props:{},children:[{type:a,value:"特定消息只能由最多一个消费者消费"}]},{type:a,value:"。 一旦消费者读取队列中的消息，它就从该队列中消失。 该系统的典型示例是订单处理系统，其中每个订单将由一个订单处理器处理，但多个订单处理器也可以同时工作。 下图描述了结构。"}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:t,props:{alt:"20190528155903014387081.jpg",src:"https:\u002F\u002Fcdn.jsdelivr.net\u002Fgh\u002Fquicktouch\u002Fimage@main\u002Fimg\u002F20190528155903014387081.jpg"},children:[]}]},{type:a,value:c},{type:b,tag:r,props:{id:y},children:[{type:b,tag:g,props:{href:"#%E5%8F%91%E5%B8%83---%E8%AE%A2%E9%98%85%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F",ariaHidden:h,tabIndex:i},children:[{type:b,tag:j,props:{className:[k,l]},children:[]}]},{type:a,value:z}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"消息被保留在主题中。 与点对点系统不同，消费者可以订阅一个或多个主题并使用该主题中的所有消息。 在发布 - 订阅系统中，"},{type:b,tag:s,props:{},children:[{type:a,value:"消息生产者称为发布者"}]},{type:a,value:"，"},{type:b,tag:s,props:{},children:[{type:a,value:"消息使用者称为订阅者"}]},{type:a,value:"。 一个现实生活的例子是Dish电视，它发布不同的渠道，如运动，电影，音乐等，任何人都可以订阅自己的频道集，并获得他们订阅的频道时可用。"}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:t,props:{alt:"20190528155903034478144.jpg",src:"https:\u002F\u002Fcdn.jsdelivr.net\u002Fgh\u002Fquicktouch\u002Fimage@main\u002Fimg\u002F20190528155903034478144.jpg"},children:[]}]},{type:a,value:c},{type:b,tag:G,props:{id:A},children:[{type:b,tag:g,props:{href:"#kafka",ariaHidden:h,tabIndex:i},children:[{type:b,tag:j,props:{className:[k,l]},children:[]}]},{type:a,value:B}]},{type:a,value:c},{type:b,tag:r,props:{id:p},children:[{type:b,tag:g,props:{href:"#%E7%AE%80%E4%BB%8B",ariaHidden:h,tabIndex:i},children:[{type:b,tag:j,props:{className:[k,l]},children:[]}]},{type:a,value:p}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"Apache Kafka是一个分布式发布 - 订阅消息系统和一个强大的队列，可以处理大量的数据，并使您能够将消息从一个端点传递到另一个端点。 Kafka适合离线和在线消息消费。 Kafka消息保留在磁盘上，并在群集内复制以防止数据丢失。 Kafka构建在ZooKeeper同步服务之上。 它与Apache Storm和Spark非常好地集成，用于实时流式数据分析。"}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:g,props:{href:"https:\u002F\u002Fsegmentfault.com\u002Fa\u002F1190000016349824",rel:[C,D,E],target:F},children:[{type:a,value:"zookeeper理解"}]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"好处"}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"以下是Kafka的几个好处"}]},{type:a,value:c},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"可靠性 - Kafka是分布式，分区，复制和容错的。"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"可扩展性 - Kafka消息传递系统轻松缩放，无需停机。"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"耐用性 - Kafka使用分布式提交日志，这意味着消息会尽可能快地保留在磁盘上，因此它是持久的。"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"性能\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Kafka对于发布和订阅消息都具有高吞吐量。 即使存储了许多TB的消息，它也保持稳定的性能。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"Kafka非常快，并保证零停机和零数据丢失。"}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"用例"}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"Kafka可以在许多用例中使用。 其中一些列出如下 -"}]},{type:a,value:c},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"指标 - Kafka通常用于操作监控数据。 这涉及聚合来自分布式应用程序的统计信息，以产生操作数据的集中馈送。"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"日志聚合解决方案 - Kafka可用于跨组织从多个服务收集日志，并使它们以标准格式提供给多个服务器。"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"流处理 - 流行的框架(如Storm和Spark Streaming)从主题中读取数据，对其进行处理，并将处理后的数据写入新主题，供用户和应用程序使用。 Kafka的强耐久性在流处理的上下文中也非常有用。"}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:r,props:{id:q},children:[{type:b,tag:g,props:{href:"#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5",ariaHidden:h,tabIndex:i},children:[{type:b,tag:j,props:{className:[k,l]},children:[]}]},{type:a,value:q}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:b,tag:t,props:{alt:"20190528155903206748657.jpg",src:"https:\u002F\u002Fcdn.jsdelivr.net\u002Fgh\u002Fquicktouch\u002Fimage@main\u002Fimg\u002F20190528155903206748657.jpg"},children:[]}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"在上图中，主题配置为三个分区。 分区1具有两个偏移因子0和1.分区2具有四个偏移因子0,1,2和3.分区3具有一个偏移因子0.副本的id与承载它的服务器的id相同。"}]},{type:a,value:c},{type:b,tag:e,props:{},children:[{type:a,value:"假设，如果主题的复制因子设置为3，那么Kafka将创建每个分区的3个相同的副本，并将它们放在集群中以使其可用于其所有操作。 为了平衡集群中的负载，每个代理都存储一个或多个这些分区。 多个生产者和消费者可以同时发布和检索消息。"}]},{type:a,value:c},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Topics（主题）\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"属于特定类别的消息流称为主题。 数据存储在主题中。主题被拆分成分区。 对于每个主题，Kafka保存一个分区的数据。 每个这样的分区包含不可变有序序列的消息。 分区被实现为具有相等大小的一组分段文件。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Partition （分区）\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"主题可能有许多分区，因此它可以处理任意数量的数据。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Partition offset（分区偏移）\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"每个分区消息具有称为 offset 的唯一序列标识"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Replicas of partition（分区备份）\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"副本只是一个分区的备份。 副本从不读取或写入数据。 它们用于防止数据丢失。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Brokers(代理)\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"代理是负责维护发布数据的简单系统。 每个代理中的每个主题可以具有零个或多个分区。 假设，如果在一个主题和N个代理中有N个分区，每个代理将有一个分区。假设在一个主题中有N个分区并且多于N个代理(n + m)，则第一个N代理将具有一个分区，并且下一个M代理将不具有用于该特定主题的任何分区。假设在一个主题中有N个分区并且小于N个代理(n-m)，每个代理将在它们之间具有一个或多个分区共享。 由于代理之间的负载分布不相等，不推荐使用此方案。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Kafka Cluster（Kafka集群）\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Kafka有多个代理被称为Kafka集群。 可以扩展Kafka集群，无需停机。 这些集群用于管理消息数据的持久性和复制。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Producers（生产者\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"生产者是发送给一个或多个Kafka主题的消息的发布者。 生产者向Kafka经纪人发送数据。 每当生产者将消息发布给代理时，代理只需将消息附加到最后一个段文件。 实际上，该消息将被附加到分区。 生产者还可以向他们选择的分区发送消息。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Consumers（消费者）\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Consumers从经纪人处读取数据。 消费者订阅一个或多个主题，并通过从代理中提取数据来使用已发布的消息。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Leader（领导者\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Leader 是负责给定分区的所有读取和写入的节点。 每个分区都有一个服务器充当Leader"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Follower（追随者\n"},{type:b,tag:f,props:{},children:[{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"跟随领导者指令的节点被称为Follower。 如果领导失败，一个追随者将自动成为新的领导者。 跟随者作为正常消费者，拉取消息并更新其自己的数据存储。"}]},{type:a,value:c}]},{type:a,value:c}]},{type:a,value:c}]}]},dir:"\u002Fwiki\u002FJava\u002F3part",path:H,extension:".md",createdAt:I,updatedAt:I},prev:{slug:J,title:K,date:L},next:{slug:M,title:N,date:O},scrollTop:P,sideCategory:[{folderName:Q,articles:[{slug:"Java-java-8-install-on-centos",title:"阿里云centos上安装jdk1.8（yum）",date:"2019-09-16T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FJava-java-8-install-on-centos"},{slug:"Java-java-mvn-proxy",title:"mvn走代理的方法",date:"2019-06-08T18:54:39.000Z",path:"\u002Fwiki\u002FJava\u002FJava-java-mvn-proxy"},{slug:"Java-java-plan",title:"JAVA学习路线",date:"2019-05-17T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FJava-java-plan"}],children:[{folderName:"3part",articles:[{slug:u,title:v,date:w,path:H},{slug:"3part-类库reflections的使用",title:"类库reflections的使用",date:R,path:"\u002Fwiki\u002FJava\u002F3part\u002F3part-类库reflections的使用"}],children:[]},{folderName:Q,articles:[{slug:"Java-Collection及其衍生",date:"2020-10-23T06:09:35.000Z",title:"Collection及其衍生",path:"\u002Fwiki\u002FJava\u002FJava\u002FJava-Collection及其衍生"}],children:[]},{folderName:"Mybatis",articles:[{slug:"Mybatis-mybatis-dyna-sql",title:"mybatis中#和$的简单理解",date:"2019-07-02T10:08:02.000Z",path:"\u002Fwiki\u002FJava\u002FMybatis\u002FMybatis-mybatis-dyna-sql"},{slug:"Mybatis-mybatis-foreach",title:"mybatis中foreach以及注意事项",date:"2019-07-02T09:59:01.000Z",path:"\u002Fwiki\u002FJava\u002FMybatis\u002FMybatis-mybatis-foreach"},{slug:"Mybatis-mybatis-resultmap",title:"mybatis一对多、一对一",date:S,path:"\u002Fwiki\u002FJava\u002FMybatis\u002FMybatis-mybatis-resultmap"}],children:[]},{folderName:"Redis",articles:[{slug:M,title:N,date:O,path:"\u002Fwiki\u002FJava\u002FRedis\u002FRedis-redis-basic"},{slug:"Redis-redis-jedis",title:"2.Redis客户端：Jedis",date:"2019-06-05T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FRedis\u002FRedis-redis-jedis"},{slug:"Redis-redis-sping-cache",title:"3.Spring中的缓存抽象及SpringDataRedis使用",date:"2019-06-06T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FRedis\u002FRedis-redis-sping-cache"}],children:[]},{folderName:"Spring",articles:[{slug:"Spring-SpringMVC中的ModelModelMapModelAndView",date:"2020-10-26T08:54:36.000Z",title:"SpringMVC中的Model、ModelMap、ModelAndView(转载)",path:"\u002Fwiki\u002FJava\u002FSpring\u002FSpring-SpringMVC中的ModelModelMapModelAndView"},{slug:"Spring-java-requestmap",title:"Java @RequestMapping、@GetMapping、@PostMapping",date:"2019-07-04T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FSpring\u002FSpring-java-requestmap"},{slug:"Spring-java-static-autowired",title:"Spring @Autowired注解在utils静态工具类非controller普通类中使用(转）",date:"2020-01-02T16:47:10.000Z",path:"\u002Fwiki\u002FJava\u002FSpring\u002FSpring-java-static-autowired"},{slug:"Spring-spring-validation",title:"spring之表单验证",date:"2019-06-14T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FSpring\u002FSpring-spring-validation"},{slug:"Spring-springboot-jsonconvert",title:"springboot之Json转换类型嵌套问题",date:"2019-06-17T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FSpring\u002FSpring-springboot-jsonconvert"},{slug:"Spring-springboot-kaptcha",title:"springboot之kaptcha验证码",date:"2019-05-22T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FSpring\u002FSpring-springboot-kaptcha"},{slug:"Spring-springboot-schedule",title:"spring框中简单的任务调度",date:"2019-09-25T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002FSpring\u002FSpring-springboot-schedule"}],children:[]},{folderName:"idea",articles:[{slug:"idea-2019-01-28",title:"(JB)idea添加项目依赖、以及打包问题",date:"2019-01-28T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002Fidea\u002Fidea-2019-01-28"},{slug:"idea-error-javacTask-x",title:"[idea] 编译报错 javacTask:源发行版 8 需要目标发行版 1.8",date:R,path:"\u002Fwiki\u002FJava\u002Fidea\u002Fidea-error-javacTask-x"},{slug:J,title:K,date:L,path:"\u002Fwiki\u002FJava\u002Fidea\u002Fidea-idea-j-warnning"},{slug:"idea-idea-svn",title:"(JB)IDEA导入svn项目二三谈",date:S,path:"\u002Fwiki\u002FJava\u002Fidea\u002Fidea-idea-svn"},{slug:"idea-springboot-start",title:"intelliJ idea:springboot项目初始化",date:"2018-10-26T13:56:11.000Z",path:"\u002Fwiki\u002FJava\u002Fidea\u002Fidea-springboot-start"}],children:[]},{folderName:"代码段",articles:[{slug:"代码段-java-8-rsa",title:"rsa加密解密",date:"2019-09-10T00:00:00.000Z",path:"\u002Fwiki\u002FJava\u002F代码段\u002F代码段-java-8-rsa"},{slug:"代码段-springboot-download-config",title:"(spring boot)虚拟目录配置、文件下载",date:"2019-01-29T17:23:27.000Z",path:"\u002Fwiki\u002FJava\u002F代码段\u002F代码段-springboot-download-config"}],children:[]},{folderName:"微服务",articles:[{slug:"微服务-feign-pass-http-header",title:"feign请求头丢失",date:"2019-01-28T16:24:12.000Z",path:"\u002Fwiki\u002FJava\u002F微服务\u002F微服务-feign-pass-http-header"}],children:[]}]}]}],fetch:{},mutations:P}}("text","element","\n","li","p","ul","a","true",-1,"span","icon","icon-link","消息系统","点对点消息系统",3,"简介","基本概念","h3","code","img","3part-kafka-basic","kafka基本概念理解","2019-05-28T00:00:00.000Z",2,"发布---订阅消息系统","发布 - 订阅消息系统","kafka","Kafka","nofollow","noopener","noreferrer","_blank","h2","\u002Fwiki\u002FJava\u002F3part\u002F3part-kafka-basic","2021-10-15T10:03:44.800Z","idea-idea-j-warnning","intelliJ IDEA:JAVA文件名黄色J警告问题","2019-05-27T00:00:00.000Z","Redis-redis-basic","1.Redis基本理解及使用","2019-06-04T00:00:00.000Z",void 0,"Java","2019-03-15T09:36:52.000Z","2018-11-06T14:47:57.000Z")));